{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0_I7ZCvEQ-Z",
        "outputId": "7aff1d75-38a7-4ae0-b633-802d8f60b2ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Oct 16 13:53:53 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_Fz1P_OEjc6",
        "outputId": "b3e25a3f-5049-43d8-eaee-64e4bd49b364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch rand distribution 0-1\n",
        "n = torch.rand(5,4,5)"
      ],
      "metadata": {
        "id": "2mBk8MhcFdbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7i38xuzNITb",
        "outputId": "b26bece0-1b90-4a9f-80ec-965f5d6a3e5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0975, 0.0405, 0.7503, 0.5726, 0.1440],\n",
              "         [0.6475, 0.0513, 0.8773, 0.0425, 0.5532],\n",
              "         [0.6829, 0.8788, 0.2952, 0.5665, 0.4604],\n",
              "         [0.4042, 0.8695, 0.6164, 0.3985, 0.9984]],\n",
              "\n",
              "        [[0.5201, 0.2463, 0.7638, 0.6277, 0.0969],\n",
              "         [0.2755, 0.6954, 0.8538, 0.0120, 0.0978],\n",
              "         [0.7425, 0.2090, 0.9336, 0.5537, 0.7423],\n",
              "         [0.3825, 0.4377, 0.3247, 0.8933, 0.4682]],\n",
              "\n",
              "        [[0.0463, 0.9908, 0.8739, 0.1045, 0.8834],\n",
              "         [0.6413, 0.4051, 0.9016, 0.4984, 0.6302],\n",
              "         [0.8664, 0.1140, 0.0244, 0.8588, 0.1589],\n",
              "         [0.2788, 0.0195, 0.9898, 0.7728, 0.9693]]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiunowDBNN57",
        "outputId": "bdf4e558-48d9-4adc-8fb6-2b7531d78e71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = torch.ones(1,2)"
      ],
      "metadata": {
        "id": "xudVoFL_NQSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5oJovS-S_Un",
        "outputId": "110760ee-e962-4795-839c-bd2989087d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = torch.arange(1,11,2)\n",
        "k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey5FrDp4TAIK",
        "outputId": "b0d2eed2-2adb-4bee-c915-fe95ed95bcc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 3, 5, 7, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Important##\n",
        "p = torch.zeros_like(k)\n",
        "p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncqte_3DTHSG",
        "outputId": "dc39285f-15ec-44ec-e6b5-2b39670726b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_32 = torch.tensor(range(1,6),dtype=torch.float32)\n",
        "float_32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIaMFgrpTQbi",
        "outputId": "7a01b30d-2605-46b6-a12d-8837981ae6ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4., 5.])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_16 = float_32.type(torch.float16)\n",
        "float_16\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kj33m_-WA2d",
        "outputId": "62a56662-b625-4d13-93b5-8365d2328e56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4., 5.], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_16.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVAWyQuFWXHp",
        "outputId": "12a7e6d4-ce52-49d3-d624-a5b8e060426e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = float_32 * float_16\n",
        "a.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsR-Umx9WeZ1",
        "outputId": "bb52cf45-a3e6-48e0-a184-18a055b91502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_rand = torch.randn(size = (224,224,3))\n",
        "#now rearrange the dimensions\n",
        "x_new = x_rand.permute(dims=(2,0,1))\n",
        "print(x_rand.shape)\n",
        "print(x_new.shape)\n",
        "# it shares the same memory/variable."
      ],
      "metadata": {
        "id": "SohNnTfEWk7F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdccab8c-5ffd-4020-9e94-5c5012f56cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([224, 224, 3])\n",
            "torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(size = (1,1,4))\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvjmc9VH3JJw",
        "outputId": "a96588e4-dc02-4878-94e7-4299e320c909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.3649, 0.2141, 0.6881, 0.5286]]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.squeeze()\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyjWSKAV1Snd",
        "outputId": "290d3c66-676b-4c93-c0f0-517f3767b453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3649, 0.2141, 0.6881, 0.5286])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " x = x.unsqueeze(dim=0)\n",
        " x,x.shape\n",
        " # 0 adds dimensions to the front , 1 adds dimensions to the back\n",
        " #interpret fromt the equations."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOWRIdiF3bbW",
        "outputId": "fc1bf7dc-30a2-45dd-ef7c-05423f6061d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.3649, 0.2141, 0.6881, 0.5286]]]), torch.Size([1, 1, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#random seed is not true randomness\n",
        "import torch"
      ],
      "metadata": {
        "id": "N0RIEEz54C84"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rand_seed = 42\n",
        "torch.manual_seed(Rand_seed)\n",
        "a = torch.rand(3,4)\n",
        "b = torch.rand(3,4)\n",
        "\n",
        "print(a)\n",
        "print(b)\n",
        "print(a == b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI0G_8qYDlQG",
        "outputId": "c673cb80-333c-4fdc-9578-616fe7e6b9c7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n",
            "        [0.8854, 0.5739, 0.2666, 0.6274],\n",
            "        [0.2696, 0.4414, 0.2969, 0.8317]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#But if we add an extra random seed in between a and b\n",
        "Rand_seed = 1\n",
        "torch.manual_seed(Rand_seed)\n",
        "a = torch.rand(3,4)\n",
        "torch.manual_seed(Rand_seed)\n",
        "b = torch.rand(3,4)\n",
        "print(a)\n",
        "print(b)\n",
        "print(a == b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHrBrgxlJ0OY",
        "outputId": "0afc0d81-0bd9-432e-f237-b945302dbc24"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7576, 0.2793, 0.4031, 0.7347],\n",
            "        [0.0293, 0.7999, 0.3971, 0.7544],\n",
            "        [0.5695, 0.4388, 0.6387, 0.5247]])\n",
            "tensor([[0.7576, 0.2793, 0.4031, 0.7347],\n",
            "        [0.0293, 0.7999, 0.3971, 0.7544],\n",
            "        [0.5695, 0.4388, 0.6387, 0.5247]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#so random seed works only for a single following random command\n",
        "#now trying the other method"
      ],
      "metadata": {
        "id": "tXb1sp8NKCtP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rand_seed = 1\n",
        "torch.manual_seed(Rand_seed)\n",
        "a = torch.rand(3,4)\n",
        "torch.manual_seed(Rand_seed)\n",
        "b = torch.rand(3,4)\n",
        "c = torch.rand(3,4)\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "print(a == b)\n",
        "print(b == c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZKbgwckKX2v",
        "outputId": "0e53c6a2-dce2-46f7-8eb7-34587bda68c8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7576, 0.2793, 0.4031, 0.7347],\n",
            "        [0.0293, 0.7999, 0.3971, 0.7544],\n",
            "        [0.5695, 0.4388, 0.6387, 0.5247]])\n",
            "tensor([[0.7576, 0.2793, 0.4031, 0.7347],\n",
            "        [0.0293, 0.7999, 0.3971, 0.7544],\n",
            "        [0.5695, 0.4388, 0.6387, 0.5247]])\n",
            "tensor([[0.6826, 0.3051, 0.4635, 0.4550],\n",
            "        [0.5725, 0.4980, 0.9371, 0.6556],\n",
            "        [0.3138, 0.1980, 0.4162, 0.2843]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# but what if we introduce a new seed in between b,c too"
      ],
      "metadata": {
        "id": "Tgq9khrbKiur"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rand_seed = 1\n",
        "torch.manual_seed(Rand_seed)\n",
        "a = torch.rand(3,4)\n",
        "torch.manual_seed(Rand_seed)\n",
        "b = torch.rand(3,4)\n",
        "torch.manual_seed(Rand_seed)\n",
        "c = torch.rand(3,4)\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "print(a == b)\n",
        "print(b == c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdUhPvnLKtND",
        "outputId": "aaa8f40c-d5bc-476b-fb16-b5fb93f59fde"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7576, 0.2793, 0.4031, 0.7347],\n",
            "        [0.0293, 0.7999, 0.3971, 0.7544],\n",
            "        [0.5695, 0.4388, 0.6387, 0.5247]])\n",
            "tensor([[0.7576, 0.2793, 0.4031, 0.7347],\n",
            "        [0.0293, 0.7999, 0.3971, 0.7544],\n",
            "        [0.5695, 0.4388, 0.6387, 0.5247]])\n",
            "tensor([[0.7576, 0.2793, 0.4031, 0.7347],\n",
            "        [0.0293, 0.7999, 0.3971, 0.7544],\n",
            "        [0.5695, 0.4388, 0.6387, 0.5247]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#so it's done now and it's clear"
      ],
      "metadata": {
        "id": "7aqewxkrKxNh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Accessing A GPU's"
      ],
      "metadata": {
        "id": "nrxsOlgSK4DJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkzUB3QDK8eo",
        "outputId": "b530467f-6fd6-4cd2-dc98-863554e8a753"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKMy0JvUM60V",
        "outputId": "ab2dc9f8-7dac-4139-8464-eed7f599aeb2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct 21 06:21:13 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P8    11W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V2ofRk9qM-re",
        "outputId": "1a6e4760-72c6-4e6b-f65d-87ff702ba9d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#putting tensor in the GPU, for faster computations"
      ],
      "metadata": {
        "id": "7WELxbzBNtwO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([1,2,3])\n",
        "t.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBRg12BKO_HN",
        "outputId": "f5f819f0-f228-4521-8e77-ccc772317008"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "P7lxrmbUPqcy",
        "outputId": "2d9c3859-7105-49b6-ef46-5d515dacd392"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_gpu = t.to(device)\n",
        "t_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27s9pX_pPNTh",
        "outputId": "223692c4-c0c1-4315-d064-55d1cddfa3dd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_return = t.cpu()\n",
        "t_return #Important"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lDEUpAuPsS2",
        "outputId": "8cd219d8-cae0-4707-bb38-19f01f830a27"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_return.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bu6GRv5SSto",
        "outputId": "14e863e1-298f-4a41-c792-26f6168b1a2a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Excercise \n",
        "#5.\n",
        "Rand_seed = 1234\n",
        "torch.cuda.manual_seed(Rand_seed)"
      ],
      "metadata": {
        "id": "oi_uzxBgSWEw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rand_seed = 42\n",
        "torch.cuda.manual_seed(Rand_seed)\n",
        "a = torch.rand(3,4,device='cuda')\n",
        "#a.to(device)\n",
        "#torch.cuda.manual_seed(Rand_seed)\n",
        "b = torch.rand(3,4,device='cuda')\n",
        "#b.to(device)\n",
        "print(a)\n",
        "print(b)\n",
        "print(a==b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac-wf8qTTX0Z",
        "outputId": "8898b47f-f93e-44a4-af8a-b167670edc4b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6130, 0.0101, 0.3984, 0.0403],\n",
            "        [0.1563, 0.4825, 0.7362, 0.4060],\n",
            "        [0.5189, 0.2867, 0.2416, 0.9228]], device='cuda:0')\n",
            "tensor([[0.9877, 0.1289, 0.5621, 0.5221],\n",
            "        [0.7445, 0.5955, 0.9647, 0.8979],\n",
            "        [0.7730, 0.6681, 0.5462, 0.5071]], device='cuda:0')\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random seed works similiar to as in CPU , just use device in rand so, it will create the tensor in the Gpu"
      ],
      "metadata": {
        "id": "lLt0mHfAU9zT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = torch.matmul(a,b.T)\n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNLP9slYW9IH",
        "outputId": "9f876933-9b66-48fb-bd64-acff878c0c7d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8517, 0.8829, 0.7186],\n",
              "        [0.8424, 1.4784, 1.0512],\n",
              "        [1.1671, 1.6187, 1.1926]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d = torch.argmax(c)"
      ],
      "metadata": {
        "id": "Z_wLUyhVXKXH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c.shape,d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xVbYiX1XZrk",
        "outputId": "b1c7c3ec-0f6e-4033-9e18-0126ffff41a2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 3]), tensor(7, device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = c.squeeze()\n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAu7Naf4Xds1",
        "outputId": "63dfbea9-5f76-4db2-dd3a-56c7c17d7e69"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8517, 0.8829, 0.7186],\n",
              "        [0.8424, 1.4784, 1.0512],\n",
              "        [1.1671, 1.6187, 1.1926]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjYajZvaXiJd",
        "outputId": "bf227f7f-a247-4857-c06f-f6ce4c781ff0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = c.flatten()\n",
        "print(f\"max\",{c[d]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hK_vKmptX568",
        "outputId": "92d8c3a7-d121-4673-f59e-9a8b8cd3639e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max {tensor(1.6187, device='cuda:0')}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d = torch.argmin(c)\n",
        "c[d]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAdS_5XBYEcw",
        "outputId": "de82f8d5-0e2a-47cf-d907-3955d76e15ea"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7186, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#10th exercise\n",
        "rt = torch.rand(1,1,1,10)\n",
        "print(rt,rt.shape)\n",
        "print(\"now\\n\")\n",
        "rt = torch.squeeze(rt,0)\n",
        "print(rt,rt.shape)\n",
        "print(\"now\\n\")\n",
        "rt = torch.squeeze(rt,0)\n",
        "print(rt,rt.shape)\n",
        "print(\"now\\n\")\n",
        "rt = torch.squeeze(rt,0)\n",
        "print(rt,rt.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2wYe8YAYrjn",
        "outputId": "9c60ea35-f8c2-4421-a44f-f362dc03c1e8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0.8045, 0.0688, 0.2405, 0.5678, 0.0188, 0.3875, 0.6440, 0.2094,\n",
            "           0.3048, 0.9919]]]]) torch.Size([1, 1, 1, 10])\n",
            "now\n",
            "\n",
            "tensor([[[0.8045, 0.0688, 0.2405, 0.5678, 0.0188, 0.3875, 0.6440, 0.2094,\n",
            "          0.3048, 0.9919]]]) torch.Size([1, 1, 10])\n",
            "now\n",
            "\n",
            "tensor([[0.8045, 0.0688, 0.2405, 0.5678, 0.0188, 0.3875, 0.6440, 0.2094, 0.3048,\n",
            "         0.9919]]) torch.Size([1, 10])\n",
            "now\n",
            "\n",
            "tensor([0.8045, 0.0688, 0.2405, 0.5678, 0.0188, 0.3875, 0.6440, 0.2094, 0.3048,\n",
            "        0.9919]) torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DiCbe-PnZplN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}