{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "111fqhsHwoJ4tCKvG7iLojrj8njQb3DR6",
      "authorship_tag": "ABX9TyMjFxa48v/EtwzKVPJY3nVL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baveet256/Pytorch-DL/blob/main/Face_emotion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc6LaH-ujlac"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcONMw8Gjqsn",
        "outputId": "6f04ddf2-80ee-4a66-a995-e1f3b7d22422"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "dir_path = Path(\"/content/drive/MyDrive/Face_Dataset\")\n",
        "unzip_path = dir_path / \"unzipped\"\n",
        "\n",
        "if unzip_path.is_dir():\n",
        "    print(\"is there\")\n",
        "else:  \n",
        "  unzip_path.mkdir(parents=True, exist_ok=True)\n",
        "  with zipfile.ZipFile(\"/content/drive/MyDrive/ Face_Dataset/archive.zip\") as f:\n",
        "    f.extractall(unzip_path)"
      ],
      "metadata": {
        "id": "FypB9cKVBXw0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "VghtxaV1--lk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "data_path = Path(\"/content/drive/MyDrive/Face_Dataset/unzipped\")"
      ],
      "metadata": {
        "id": "ifij_WHt-Vsk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor() \n",
        "])"
      ],
      "metadata": {
        "id": "xm7Q0lSE8Nvc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = data_path / \"train\"\n",
        "test_dir = data_path / \"test\""
      ],
      "metadata": {
        "id": "tcNByO5KAKMj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfNiGgEoATPM",
        "outputId": "ddd984b9-825d-4600-d411-d219d7ec4b1a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/drive/MyDrive/Face_Dataset/unzipped/train')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.ImageFolder(root=train_dir,transform=data_transform,target_transform=None)\n",
        "test_data = datasets.ImageFolder(root=test_dir,transform=data_transform)\n",
        "\n",
        "print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTRpLGOS5NUy",
        "outputId": "e5012c4b-e227-44e3-c38c-abc1f2bcd802"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data:\n",
            "Dataset ImageFolder\n",
            "    Number of datapoints: 28709\n",
            "    Root location: /content/drive/MyDrive/Face_Dataset/unzipped/train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Grayscale(num_output_channels=1)\n",
            "               RandomHorizontalFlip(p=0.5)\n",
            "               ToTensor()\n",
            "           )\n",
            "Test data:\n",
            "Dataset ImageFolder\n",
            "    Number of datapoints: 7178\n",
            "    Root location: /content/drive/MyDrive/Face_Dataset/unzipped/test\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Grayscale(num_output_channels=1)\n",
            "               RandomHorizontalFlip(p=0.5)\n",
            "               ToTensor()\n",
            "           )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SKMFGDOEtG1",
        "outputId": "9a022573-baea-43ef-ef00-fda6ee763196"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0O2zEnLFCZV",
        "outputId": "531882b9-bdc1-4150-bebd-5ec4ee8d9164"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 48, 48])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to visualize we will do matplotlib\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Ix6-jvIjFMlS"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img,label = train_data[0][0],train_data[0][1]\n",
        "img_new = img.permute(1,2,0).squeeze(dim=2)\n",
        "print(img_new.shape)\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(img_new, cmap='gray')\n",
        "plt.axis(\"off\")\n",
        "plt.title(class_names[label], fontsize=14);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "fjEGvLwLFp_d",
        "outputId": "1115af17-5145-4565-ccf7-fbfebf086019"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([48, 48])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(dataset=train_data,batch_size=32,shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_data,batch_size=32,shuffle=True)"
      ],
      "metadata": {
        "id": "Ju_GL-sMGRvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Emotionmodel(nn.Module):\n",
        "  def __init__(self,input_channels:int,out_channel:int):\n",
        "    super().__init__()\n",
        "    self.layer_stack1 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=input_channels,out_channels=32, kernel_size = 3, padding =1, stride=1),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(in_channels=32,out_channels=64, kernel_size = 3, padding =1, stride=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2),\n",
        "      nn.Dropout(p=0.25),\n",
        "    )\n",
        "    self.layer_stack2 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels=64,out_channels=128, kernel_size = 3, padding =1, stride=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2),\n",
        "      nn.Conv2d(in_channels=128,out_channels=128, kernel_size = 3, padding =1, stride=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2),\n",
        "      nn.Dropout(p=0.25),\n",
        "    )\n",
        "    self.layer_stack3 = nn.Sequential(\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(in_features = 1024,out_features=256),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(p=0.5),\n",
        "      nn.Linear(in_features =256 ,out_features=7),\n",
        "      nn.Softmax(dim=1)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    x = self.layer_stack1(x)\n",
        "    print(x.shape)\n",
        "    x = x.unsqueeze(dim=0)\n",
        "    print(x.shape)\n",
        "    x = self.layer_stack1(x)\n",
        "    print(x.shape)\n",
        "    x = self.layer_stack1(x)\n",
        "    print(x.shape)\n",
        "    return x"
      ],
      "metadata": {
        "id": "BgbQWoXsKRgP"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_conv = Emotionmodel(1,out_channel = len(train_data.classes))\n",
        "model_conv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yky3zcZPbxv",
        "outputId": "617822ab-53ba-41b9-f41c-8c4cbda55610"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Emotionmodel(\n",
              "  (layer_stack1): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Dropout(p=0.25, inplace=False)\n",
              "  )\n",
              "  (layer_stack2): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Dropout(p=0.25, inplace=False)\n",
              "  )\n",
              "  (layer_stack3): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=1024, out_features=256, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=256, out_features=7, bias=True)\n",
              "    (5): Softmax(dim=1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLZe6wTGTKso",
        "outputId": "50fb0a83-9f47-4bfa-a29b-2a0754116963"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 48, 48])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_conv(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "50RI1PKTTOkJ",
        "outputId": "1f120a56-2afc-4b60-b4a9-55895061b488"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 24, 24])\n",
            "torch.Size([1, 64, 24, 24])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-515b78973293>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-63-51d96528bf54>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_stack1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_stack1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    453\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 454\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 1, 3, 3], expected input[1, 64, 24, 24] to have 1 channels, but got 64 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trail = torch.tensor([64, 24, 24])\n",
        "trail.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNoveSMoTY2I",
        "outputId": "f57995f9-dff7-4092-8f81-d1dc79fbafbf"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trail.unsqueeze(dim=0).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1bF_q_YVAqK",
        "outputId": "f4e50876-d911-4a95-92e7-164d63628791"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VJStSn8OVFWL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}